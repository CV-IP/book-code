{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])])\n",
    "dataset_train = datasets.MNIST(root = \"./data\",\n",
    "transform = transform,\n",
    "train = True,\n",
    "download = True)\n",
    "dataset_test = datasets.MNIST(root = \"./data\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transform,\n",
    "train = False)\n",
    "train_load = torch.utils.data.DataLoader(dataset = dataset_train,\n",
    "batch_size = 64,\n",
    "shuffle = True)\n",
    "test_load = torch.utils.data.DataLoader(dataset = dataset_test,\n",
    "batch_size = 64,\n",
    "shuffle = True)\n",
    "images, label = next(iter(train_load))\n",
    "images_example = torchvision.utils.make_grid(images)\n",
    "images_example = images_example.numpy().transpose(1,2,0)\n",
    "mean = [0.5,0.5,0.5]\n",
    "std = [0.5,0.5,0.5]\n",
    "images_example = images_example*std + mean\n",
    "plt.imshow(images_example)\n",
    "plt.show()\n",
    "class RNN(torch.nn.Module):\n",
    "def __init__(self):\n",
    "super(RNN, self).__init__()\n",
    "self.rnn = torch.nn.RNN(\n",
    "input_size = 28,\n",
    "hidden_size = 128,\n",
    "num_layers = 1,\n",
    "batch_first = True\n",
    ")\n",
    "self.output = torch.nn.Linear(128,10)\n",
    "def forward(self, input):\n",
    "output,_ = self.rnn(input, None)\n",
    "output = self.output(output[:,-1,:])\n",
    "return output\n",
    "model = RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_f = torch.nn.CrossEntropyLoss()\n",
    "epoch_n =10\n",
    "for epoch in range(epoch_n):\n",
    "running_loss = 0.0\n",
    "running_correct = 0\n",
    "testing_correct = 0\n",
    "print(\"Epoch {}/{}\".format(epoch, epoch_n))\n",
    "print(\"-\"*10)\n",
    "for data in train_load:\n",
    "X_train,y_train = data\n",
    "X_train = X_train.view(-1,28,28)\n",
    "X_train,y_train = Variable(X_train),Variable(y_train)\n",
    "y_pred = model(X_train)\n",
    "loss = loss_f(y_pred, y_train)\n",
    "_,pred = torch.max(y_pred.data,1)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "running_loss +=loss.data[0]\n",
    "running_correct += torch.sum(pred == y_train.data)\n",
    "for data in test_load:\n",
    "X_test, y_test = data\n",
    "X_test = X_test.view(-1,28,28)\n",
    "X_test, y_test = Variable(X_test), Variable(y_test)\n",
    "outputs = model(X_test)\n",
    "_, pred = torch.max(outputs.data, 1)\n",
    "testing_correct += torch.sum(pred == y_test.data)\n",
    "print(\"Loss is:{:.4f}, Train Accuracy is:{:.4f}%, Test Accuracy\n",
    "is:{:.4f}\".format(running_loss/len(dataset_train),100*running_correct/len(da\n",
    "taset_train),100*testing_correct/len(dataset_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
